import requests
from bs4 import BeautifulSoup
import re
import time  # æ·»åŠ è¿™è¡Œå¯¼å…¥

# é…ç½®éƒ¨åˆ†
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
}
TARGETS = [
    'https://www.wetest.vip/page/cloudflare/address_v4.html',
    'https://ip.164746.xyz',
    'https://api.uouin.com/cloudflare.html'  # æ³¨æ„ï¼šè¯¥ç«™ç‚¹æœ‰1ç§’å»¶è¿Ÿåˆ·æ–°
]

def extract_ips(text):
    """ä½¿ç”¨æ­£åˆ™æå–æ‰€æœ‰IPv4åœ°å€"""
    return re.findall(r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b', text)

def scrape_site(url):
    """æ ¸å¿ƒçˆ¬å–é€»è¾‘"""
    try:
        print(f"\nğŸ” æ­£åœ¨çˆ¬å–: {url}")
        
        # ç‰¹æ®Šå¤„ç†api.uouinçš„å»¶è¿ŸåŠ è½½
        delay = 1.5 if 'api.uouin.com' in url else 0
        
        response = requests.get(url, headers=HEADERS, timeout=10)
        response.raise_for_status()
        
        if delay:
            print(f"â³ ç­‰å¾… {delay}ç§’è®©æ•°æ®åˆ·æ–°...")
            time.sleep(delay)
            # éœ€è¦äºŒæ¬¡è¯·æ±‚è·å–æœ€æ–°æ•°æ®
            response = requests.get(url, headers=HEADERS, timeout=10)
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ä¼˜å…ˆä»è¡¨æ ¼è¡Œæå–
        ips = []
        for tr in soup.find_all('tr'):
            ips.extend(extract_ips(tr.get_text()))
        
        # å¤‡ç”¨æ–¹æ¡ˆï¼šå…¨å±€æœç´¢
        if not ips:
            ips = extract_ips(response.text)
            
        return list(set(ips))  # ç«‹å³å»é‡
    
    except Exception as e:
        print(f"âŒ çˆ¬å–å¤±è´¥: {str(e)}")
        return []

if __name__ == '__main__':
    all_ips = []
    
    for target in TARGETS:
        if result := scrape_site(target):
            print(f"âœ… å‘ç° {len(result)} ä¸ªIP:")
            print("\n".join(f"  - {ip}" for ip in result))
            all_ips.extend(result)
    
    # æœ€ç»ˆå»é‡ä¿å­˜
    with open('ip.txt', 'w') as f:
        f.write("\n".join(sorted(set(all_ips))))
    
    print(f"\nğŸ‰ å®Œæˆï¼å…±æ”¶é›† {len(set(all_ips))} ä¸ªå”¯ä¸€IP")
